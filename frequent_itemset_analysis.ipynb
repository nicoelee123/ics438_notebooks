{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8374ce21",
   "metadata": {},
   "source": [
    "### Mining Frequent itemsets\n",
    "\n",
    "* Based on slides from the [Mining Massive Datasets](mmds.org)\n",
    "* One of the earliest data mining applications on big data\n",
    "* The Apriori Algorithm used in Mining Frequent Itemsets is one of the most cited algorithms\n",
    "* Initial applications: find unusual sets of items purchased together in supermarkets\n",
    "  * Used for shelf management, promotions, and cross-selling, stocking, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f01f2",
   "metadata": {},
   "source": [
    "### Supermarket shelf management – Market-basket model\n",
    "\n",
    "* Goal: Identify items that are purchased together by a large number of customers\n",
    "    \n",
    "* Approach: Process the sales data collected with barcode scanners to find dependencies among items\n",
    "\n",
    "* A classic rule:  If someone buys diapers and milk, then he/she is likely to buy beer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e2c907",
   "metadata": {},
   "source": [
    "### The Co-Occurrence of Consumer Problems\n",
    "\n",
    "```\n",
    "Technological advances have drastically improved the ability for companies to collect, store, and track data on consumer behavior. As a consequence, many brands and big businesses are using massive data sets for data mining or market basket analysis. With these practices, companies are able to identify purchase patterns and relationships, such as commonly co-occurring purchases (e.g. “75% of consumers who purchase bread also purchase milk”). Knowing associated purchases subsequently allows marketers to better target consumers through direct messages or displaying certain items together. In fact, marketers already are acting upon this data, at some point we’ve all come across the “Shoppers who bought this item also bought…” while browsing products online.\n",
    "```\n",
    "\n",
    "https://www.forbes.com/sites/kurtcarlson/2015/02/05/the-co-occurrence-of-consumer-problems/?sh=33cba5cd2fac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e92c4",
   "metadata": {},
   "source": [
    "### The Market Basket: The Model\n",
    "\n",
    "* Data consisting of a *large set* of historical transaction logs \n",
    "\n",
    "* An item is a product that has been purchased\n",
    "\n",
    "* Basket refers to what a client had in a shopping basket\n",
    "  * I.e., a transaction describing the set of products someone bought in one trip to the store\n",
    " \n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/hky2v1glgcdoeht/baskets_items.png?dl=1\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb0703",
   "metadata": {},
   "source": [
    "### The Market Basket: The Model - Cont'd\n",
    "\n",
    "* We want to discover association rules\n",
    "\n",
    "* People who bought ${v, w, x}$ tend to buy ${y,z}$\n",
    "  * Naturally, this means that ${v, w, x, y, z}$ to co-occur in the same basket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244844e7",
   "metadata": {},
   "source": [
    "### Item Set Analysis Sample Applications\n",
    "\n",
    "* Chain stores keep terabytes of data about what customers buy together\n",
    "\n",
    "* Better understand purchasing habits, and among other things:\n",
    "  * Suggests tie-in “tricks”, e.g., run a sale on diapers and raise the price of beer\n",
    "  * Decide on stock levels, e.g., We should have as much milk as we have butter\n",
    "  * Decide on product placement, e.g. to increase time in store or increase distance covered. \n",
    "  * Make product recommendations, e.g., Amazon’s people who bought $X$ also bought $Y$\n",
    "  * Discounts on products to gain customers, e.g., targeted discounts to attract expecting families to become shoppers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba0cf9",
   "metadata": {},
   "source": [
    "### Using Itemset Analysis to Predict Pregnancy\n",
    "\n",
    "* [`How Target Figured Out A Teen Girl Was Pregnant Before Her Father Did`](https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/?sh=72c7066f6668)\n",
    "\n",
    "* Target assigns every customer a Guest ID number, tied to their credit card name, or email address \n",
    "  * A bucket that stores a history of everything they've bought \n",
    "    * Alternative to a loyalty program #\n",
    "\n",
    "* Information is enriched with demographic info either bought or collected internally. \n",
    "\n",
    "* Conslution: Customers buying lots of scent-free soap and extra-big bags of cotton balls, in addition to hand sanitizers and washcloths, frequently also buy (or will eventually buy) diapers\n",
    "   * Somewhat similar to women buying prenatal supplements like calcium, magnesium, and zinc \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bbc2f",
   "metadata": {},
   "source": [
    "### Other Applications\n",
    "\n",
    "* * Market basket (or association rules mining) is widely applicable across a wide range of domains\n",
    "  * Not limited to its original intended application\n",
    "\n",
    "* Baskets = patients; Items = drugs and/or side-effects\n",
    "  * Has been used to detect combinations of drugs that result in particular side-effects\n",
    "  * But requires extension: Both the presence and absence of an item needs to be encoded\n",
    "\n",
    "* Baskets = set of all daily stock transactions on the stock exchange; Items = stock\n",
    "    * Which stocks tend to express changes together\n",
    "    * Used to balance risk in a portfolio   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b2cb8",
   "metadata": {},
   "source": [
    "### The Frequent ItemSet Problem\n",
    "\n",
    "* Objective: Find sets of items that appear together “frequently” in baskets\n",
    "* What do we mean by frequently? \n",
    "  * Number of baskets containing all items in the identified set `I`\n",
    "    * This is called the `support` for item `I`\n",
    "      * `support(I)`\n",
    "    * Expressed as a fraction or percentage of all the baskets\n",
    "* Given support threshold $s$\n",
    "    * The sets of items with support `>` $s$ are called frequent itemsets    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d751f8",
   "metadata": {},
   "source": [
    "### Association Rules: a Definition (1)\n",
    "\n",
    "Association Rules is an If-then rule about the contents of baskets\n",
    "\n",
    "* If a basket contains all of $i_1, i_2, \\dots, i_j$ then it is likely to contain $k$.\n",
    "  * Written as $i_1, i_2, \\dots, i_j \\rightarrow k$  \n",
    "\n",
    "* In practice there are many possible association rules \n",
    " * We are only interested in those that are \"significant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a652a2e",
   "metadata": {},
   "source": [
    "### Association Rules Confidence\n",
    "\n",
    "* Given an itemset $I = {i_1, i_2, \\dots, i_k}$\n",
    "\n",
    "* The confidence of an association rule is the probability of $j$ given $I$\n",
    "\n",
    "\n",
    "* I.e., among all the baskets that contain the items of $I$, how many also contain $j$\n",
    "  * Or, among all the baskets how many contain the items of $I$ and $j$ together\n",
    "\n",
    "$$\n",
    " \\mbox{confidence}(I \\rightarrow j) = \\frac{\\mbox{support}(I \\cup j)}{\\mbox{support}(I)}\n",
    "$$\n",
    "\n",
    "\n",
    "* This is not a reflexive function\n",
    "  * $ \\mbox{confidence}(I \\rightarrow j) \\ne \\mbox{confidence}(j \\rightarrow I)$\n",
    "  * Diapers $\\rightarrow$ beer does not imply beer $\\rightarrow$ diapers\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c6089",
   "metadata": {},
   "source": [
    "### Interesting Associations\n",
    "\n",
    "* It goes without saying that we are also interested in interesting ones\n",
    "  * Milk is purchased very often, therefore, $X \\rightarrow milk$ may have high confidence. Is this an interesting association ?\n",
    "\n",
    "* the Interestingness of an association rule $I \\rightarrow j$ is the difference between its confidence and the fraction of baskets that contain $j$\n",
    "\n",
    "$Interest(I \\rightarrow j) = conf(I \\rightarrow j) - Pr(j)$\n",
    "\n",
    "* Interesting rules are those with high positive or negative interest values (usually above 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44882d",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "<table>\n",
    "    <tr><td style=\"text-align:left;\">$B_1 = \\{m, b, c\\}$ </td><td style=\"text-align:left;\">$B_2 = \\{m, p, j\\} $</td></tr>\n",
    "    <tr><td style=\"text-align:left;\"> $B_3 = \\{m, b\\}$\t</td> <td style=\"text-align:left;\"> $B4= \\{c, j\\}$ </td></tr>\n",
    "    <tr><td style=\"text-align:left;\"> $B_5 = \\{m, p, b\\}$</td><td style=\"text-align:left;\"> $B6 = \\{m, c, b, j\\}$</td></tr>\n",
    "    <tr><td style=\"text-align:left;\"> $B_7 = \\{c, b, j\\}$</td><td style=\"text-align:left;\"> $B_8 = \\{b, c\\}$</td></tr>\n",
    "</table>\n",
    "\n",
    "* Association rule: $\\{m, b\\} \\rightarrow c$\n",
    "$$\n",
    "\\mbox{confidence}(\\{m, b\\} \\rightarrow c) = \\frac{\\{B_1, B_6 \\}}{\\{B_1, B_3, B_5, B_6 \\}} = \\frac{2}{4}= 0.5\n",
    "$$  \n",
    "\n",
    "$$\n",
    "\\mbox{interest}(\\{m, b\\} \\rightarrow c) = 0.5 - \\frac{5}{8} = 1/8\n",
    "$$  \n",
    "\n",
    "* The item $c$ is very frequent (5/8 transactions)\n",
    "* Therefore, the rule is not very interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd808a1",
   "metadata": {},
   "source": [
    "### Lift\n",
    "\n",
    "* Another Commonly Used Statistic is the `lift`\n",
    "\n",
    "  * How much more likely is this association compared to any combination of the same size we would find by chance?\n",
    "    \n",
    "* The denominator is all the occurrences of: <br>\n",
    "    $\\mbox{support(I)} \\times \\mbox{support(j)}$\n",
    "\n",
    "* The numerator is the support of the itemset: <br>\n",
    "    $\\mbox{support}(I \\rightarrow j)$\n",
    "    \n",
    "$$\n",
    "\\mbox{lift}(I \\rightarrow j) =  \\frac{\\mbox{support}(I \\cup j)}{\\mbox{support}(I) \\times \\mbox{support}(j)} = \\frac{\\mbox{confidence}(I \\rightarrow j)}{\\mbox{support}(j)}\n",
    "$$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57bcb3",
   "metadata": {},
   "source": [
    "### Association Rules; Problem\n",
    "\n",
    "* Problem: Find all association rules such that \n",
    "  * $\\mbox{confidence}(I \\rightarrow j) \\ge c$\n",
    "  * $\\mbox{support}(I) \\ge s$\n",
    "\n",
    "* In a big data context, the computationally challenging part is finding the frequent itemsets\n",
    "  * This can be, in fact, challenging even with relatively small datasets.\n",
    "\n",
    "* Observation: if ${i_1, i_2, \\dots, i_k} \\rightarrow j$ has high support and confidence, then both {$i_1$, $i_2$, $\\dots$, $i_k$} and {$i_1$, $i_2$, $\\dots$, $i_k$, $j$} will be “frequent”\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4029c1ad",
   "metadata": {},
   "source": [
    "### Finding Frequent Itemsets\n",
    "\n",
    "* Find all frequent items $I$\n",
    "  * In the naive approach, there are $2^n -1$ subsets\n",
    "    * Clearly not tractable for as little as 40 items ($2^{40}$ = 1,099,511,627,775 possible subsets)\n",
    " \n",
    "* Many of the items in the list above will not have the desired support\n",
    "  * From the previous observation, the set containing those items will not have the desired observations\n",
    "\n",
    "* Therefore, rule out any elements without the desired support\n",
    "\n",
    "* Stores can often have thousands for products and millions of transaction\n",
    "  * Walmart has millions of SKU's (75 million SKUs as of 2018) and processes millions of transactions daily\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4fa40b",
   "metadata": {},
   "source": [
    "### Mining Association Rules\n",
    "\n",
    "* We can use the following two-step approach:\n",
    "\n",
    "1.  Find all items $I$ such that $support(I) > s_1$\n",
    "  * We assume, for now, that we have a way to generate this set.\n",
    "2. For every subset $A$ of $I$, generate a rule ${I - A} \\rightarrow A$  \n",
    "  * The association rule is is acceptable if:\n",
    "    * $support({I - A}) = s_2 \\ge s$ \n",
    "    * $s_1/s_2 \\ge c$\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a781e2",
   "metadata": {},
   "source": [
    "### The A-Priori Algorithm\n",
    "\n",
    "* The apriori algorithm is used to find all frequent itemsets\n",
    "\n",
    "* Uses the frequent itemsets to generate association rules\n",
    "  * A subset of frequent itemsets most alo be a frequent itemset\n",
    "    * Any non-empty subset of a frequent itemset is also frequent\n",
    "\n",
    "* Iteratively Build itemsets achieve a minimum support values\n",
    "  * Start with itemsets of size 1\n",
    "  * The itemsets of size 2\n",
    "  * \\etc.\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e871a6f3",
   "metadata": {},
   "source": [
    "### A priori Algorithm: Generating the Itemsets\n",
    "\n",
    "* Since baskets are typically small, we can generate all subset of a single basket:\n",
    "  * If $B_1 = \\{a,b,c\\}$ then $itemsets = \\{\\{a\\}, \\{b\\}, \\{c\\}, \\{a,b\\}, \\{a,c\\}, \\{b,c\\}\\}$\n",
    "\n",
    "* Why not start with all itemsets of size 1 or 2? \n",
    "  * If a combination never occurs, then do not include it?\n",
    "  * Starting with what's only observed in the baskets can lead to substantial speed ups\n",
    "\n",
    "* Intuition:\n",
    "  * Join Step: Joining smaller itemsets with minimum support can lead to a larger itemset that has minimum support.\n",
    "  * Pruning Step: removing items with low support can only improve the quality of an itemset.\n",
    "    * If $\\mbox{support}({i_1}) < s$ then $\\mbox{support}({i_1}\\cup A) < s$ for any subset $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469bb6e7",
   "metadata": {},
   "source": [
    "### A priori Algorithm: Generating Subsets\n",
    "\n",
    "* For each frequent itemset, generate all the subsets of size smaller than the cardinality of $|I|$\n",
    "  * E.g.:  $I= \\{m, b, c\\}$ generate subsets $S =\\{m, b\\}, \\{b, c\\}, \\{m, c\\}, \\{m\\}, \\{b\\}, \\{c\\}, $\n",
    "\n",
    "* Genete a rule $R$ such that:\n",
    "  $S \\rightarrow I-S$\n",
    "* Retain $R$ is $\\mbox{confidence}(R) > r$\n",
    "\n",
    "E.g.: Given $I= \\{m, b, c\\}$, we can constructruct Rules:\n",
    "\n",
    "$R_1 = \\{m, b\\} \\rightarrow \\{c\\}$ <br>\n",
    "$R_2 = \\{b, c\\} \\rightarrow \\{m\\}$  <br>\n",
    "$R_3 = \\{m, c\\} \\rightarrow \\{b\\}$  <br>\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ea23fa",
   "metadata": {},
   "source": [
    "### Implementation Details\n",
    "\n",
    "* Given a large number of items and long descriptions, items are  typically encoded as integers\n",
    "  ```{..., \"Mayonaise\": 330, \"Milk\": 331, \"Mustard\": 333, ...}```\n",
    "  * For space saving purposes, item are represented using  integers from 1 to $n$, where $n$ is the number of distinct items. \n",
    "* In realife, this can be a challenging problem and often requires item to be grouped into taxonomies\n",
    "  * Wikipedia: A taxonomy (or taxonomical classification) is a scheme of classification, especially a hierarchical classification, in which things are organized into groups or types. \n",
    "  * This is necessary to avoid missing rules such \n",
    "```\n",
    "Swiss Miss Milk Chocolate Flavor Hot Cocoa Mix, 41.4 Ounce (Pack of 8), Kraft Jet-Puffed Mini Marshmallows (Pack of 2) \n",
    "Nestle Hot Chocolate Packets, Milk Chocolate Flavor Hot Cocoa Mix, Bulk Pack (60 Count), 365 by Whole Foods Market, Marshmallow Large, 10 Ounce \n",
    "```\n",
    "\n",
    "Instead, encode the data as: \n",
    "```\n",
    "Hot Cocoa, Marshmallow\n",
    "Hot Cocoa, Marshmallow \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c57db24",
   "metadata": {},
   "source": [
    "### Implementation Details\n",
    "\n",
    "* Storing counts in RAM for frequent itemsets can be challenging\n",
    "  * It is not trivial to store $n \\choose 2$ -- we need space to store $n^2/2$ integers.\n",
    "     * if `int` takes 4 bytes, we need $2n^2$ bytes\n",
    "     * Upper triangular matrix\n",
    "  * For 200k items, we need 80,000,000,000 bytes $\\approx$ 75 GB\n",
    "\n",
    "* Note that most of those pairs will be null\n",
    "* * An idea when storing such data is to use triplet counting \n",
    "  * for pairs of items i and j, where $i < j$, store counts as\n",
    "\n",
    "```{(i,j) => c}```\n",
    "\n",
    "* Scales to triplets:\n",
    "  * keys can be a tuple of any size.\n",
    "    \n",
    "* See numpy implemenation of sparse mtrices:\n",
    "https://docs.scipy.org/doc/scipy/reference/sparse.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d9271",
   "metadata": {},
   "source": [
    "### Newsworthy Applications -- Cont'd\n",
    "\n",
    "* The Diapers and Beers Legend\n",
    "  * Or is it? \n",
    "    \n",
    "* Beer and Diapers: The Impossible Correlation:\n",
    "https://tdwi.org/articles/2016/11/15/beer-and-diapers-impossible-correlation.aspx    \n",
    "\n",
    "* In a very large datasets, some item sets may be due to chance, cross-promotions or other unknowns\n",
    "\n",
    "* As emphasized during the first lecture, correlations and findings in big data are to be taken carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1761f",
   "metadata": {},
   "source": [
    "### Newsworthy Applications -- Cont'd\n",
    "\n",
    "* This is not a causality but rather co-occurrence \n",
    "  * Clear in the context of the Market Basket example, despite the arrow that may be interpreted as causal, but may be less so in other contexts.\n",
    "\n",
    "* Multiple testing correction may be necessary\n",
    "  * We are testing thousands of rules, some may be correct due ot chance alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221629b3",
   "metadata": {},
   "source": [
    "### Alternative Mehtod: FP Growth Method\n",
    "\n",
    "* Finding frequent itemsets without first generating the candidate generation\n",
    "\n",
    "* Two steps: find frequent items and build the frequent-pattern tree (datastructure)\n",
    "\n",
    "* Devide the frequent-pattern tree into a set of conditional subtree\n",
    "  * Each substree focuses on one of the items\n",
    "  * process each subtreet too find frequent itemssets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cb1400",
   "metadata": {},
   "source": [
    "### Finding and Sorting Frequent Items\n",
    "\n",
    "* Sort frequent item and drop those below a certain threshold\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/dsdr0ksoam4yovf/sort_filter.png?dl=1\" width=\"400\">\n",
    "\n",
    "\n",
    "<small><p>Borgelt, Christian. \"An Implementation of the FP-growth Algorithm.\" Proceedings of the 1st international workshop on open source data mining: frequent pattern mining implementations. 2005.</small></p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab3f89",
   "metadata": {},
   "source": [
    "### Buildind and The FP Growth Tree\n",
    "\n",
    "<img src=\"https://www.dropbox.com/s/ajusioewghx1tje/build_fp_groth_tree.png?dl=1\" width=\"400\">\n",
    "\n",
    "<small><p>Borgelt, Christian. \"An Implementation of the FP-growth Algorithm.\" Proceedings of the 1st international workshop on open source data mining: frequent pattern mining implementations. 2005.</small></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b3682a",
   "metadata": {},
   "source": [
    "### Enumerating the Frequent Itemsets\n",
    "\n",
    "* For a detailed explanation of how the frequent itemsets are derived, see the following\n",
    "https://www.geeksforgeeks.org/ml-frequent-pattern-growth-algorithm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5dde81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
