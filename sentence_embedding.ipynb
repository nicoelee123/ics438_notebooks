{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20f1223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed77de7b",
   "metadata": {},
   "source": [
    "### Sentence embedding\n",
    "\n",
    "* Learning semantically reprentaitve encoding for the complete sentence\n",
    "* Naive aproach.\n",
    "  * Use exisitng information to derive a sentence embedding\n",
    "* Unsupervised approach: \n",
    "    1. reconstruct the sentence from its surrounding     \n",
    "    2. reconstruct the surrounding from the sentence \n",
    "    * in both cases an embedding is learned\n",
    "      * Sounds familair?\n",
    "    * E.g.,  IS-BERT\n",
    "* Supervised approach:\n",
    "  * Use labeled data to learn sentence similarity and in so\n",
    "    * E.g., SBERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb55751",
   "metadata": {},
   "source": [
    "### Model S\n",
    "\n",
    "* Two sequences are  set to a Transformer-based language model like BERT\n",
    "\n",
    "![](https://www.dropbox.com/s/b90fcl4gx3za4nn/learning_emebdding_basic.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ef0ff",
   "metadata": {},
   "source": [
    "# Shortcoming of cross encoder-based approach\n",
    "\n",
    "* Large space of possible combinations\n",
    "  * repeat the comparison for ech item in a DB\n",
    "  * impossible to scale for clustering\n",
    "\n",
    "* Ideally, we would like to find proper embeddings for a sentence\n",
    "  * i.e., semantically similar sentences would have a similar encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5700e",
   "metadata": {},
   "source": [
    "### Trival Approach - 1\n",
    "\n",
    "* Take the average of the token embeddings in a sentence\n",
    "  * Mean pooling\n",
    "  * Works surprisingly well for most cases \n",
    "![](https://www.dropbox.com/s/dav4bhh0uyfs805/avg_embedding.png?dl=1)\n",
    "\n",
    "* Basic intution:\n",
    "* Taking the average if all word represents the average meaning of the sentence.\n",
    "* In high dimnesional space (e.g., 768), tt is unlikely that two collection have similar meaning unless they share most of thier similar words.\n",
    "\n",
    "\n",
    "* Formal justification of the basic intuition\n",
    "https://randorithms.com/2020/11/17/Adding-Embeddings.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trival Approach - 2\n",
    "\n",
    "* Use the embedding of the CLS token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd16c6",
   "metadata": {},
   "source": [
    "### Sentence BERT\n",
    "\n",
    "\n",
    "\n",
    "* Sentence-BERT (SBERT), a modification of the BERT network using siamese and triplet networks that is able to derive semantically\n",
    "meaningful sentence embeddings, which can be used for largescale semantic similarity comparison.\n",
    "\n",
    "* Labeled data to \n",
    "\n",
    "* Model outperforms all other appproaches on most benchmarks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b67ec",
   "metadata": {},
   "source": [
    "### SBERT Training Data\n",
    "\n",
    "Use a natural language inference dataset as a training data\n",
    "\n",
    "  * given two iput sentences; a premise and a hypothesis, Natural language inference is the task consisting of detemining whether the \n",
    "    - The premise suggests the hypothesis (entailment)\n",
    "    - The premise and the hypothesis are neutral (neural)\n",
    "    - The premise and the hypothesis contridict each other (contradiction)\n",
    "\n",
    "* Used SNLI and Multi-NLI \n",
    "\n",
    "https://huggingface.co/datasets/snli\n",
    "https://huggingface.co/datasets/multi_nli\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbbbf7e",
   "metadata": {},
   "source": [
    "### SBERT Training Data\n",
    "\n",
    "* Idea: let's use this to train to predict these scenarios and by learning to predict, we can also learn a better embedding.\n",
    "\n",
    "![](https://www.dropbox.com/s/1efvtuenz4ykds1/sbert_architecture.png?dl=1)\n",
    "\n",
    "\n",
    "https://arxiv.org/pdf/1908.10084.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e54427",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SBERT Advantages and Disadvantages\n",
    "\n",
    "- Advantages:\n",
    "• Computationally efficient\n",
    "  * Fine tuning pretrained BERT on NLI data\n",
    "• Significantly better that other embedding methods.\n",
    "- Disadvantages:\n",
    "  * requires training data which may be difficult, see impossible, to come by to fine tune for a specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0464ceb",
   "metadata": {},
   "source": [
    "### Using Sentence Transformers in Python\n",
    "\n",
    "```python\n",
    "# !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"model-goes-here\")\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "See [https://www.sbert.net/docs/pretrained_models.html](https://www.sbert.net/docs/pretrained_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876e036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "636c7cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9ed160f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\"This is an improved Recipe with Dry Roasted Peanuts.\"]\n",
    "embeddings = model.encode(sentence)\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29cf994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01193995  0.0636649  -0.03732967 -0.01371691  0.00784811  0.02416359]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings[0][0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e647b96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [\n",
    "    \"3 Musketeers Milk Chocolate Bar, Full Size\", \n",
    "    \"Reese's PIECES Peanut Butter Candy\", \n",
    "    \"Lay's Classic Potato Chips, Party Size\", \n",
    "    \"Nestle mate French Vanilla Liquid Coffee\"\n",
    "]\n",
    "embeddings = model.encode(sentence)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "37dbeb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "list(itertools.combinations(range(4), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51f213d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 Musketeers Milk Chocolate Bar, Full Size</td>\n",
       "      <td>Reese's PIECES Peanut Butter Candy</td>\n",
       "      <td>0.419337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers Milk Chocolate Bar, Full Size</td>\n",
       "      <td>Lay's Classic Potato Chips, Party Size</td>\n",
       "      <td>0.358077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 Musketeers Milk Chocolate Bar, Full Size</td>\n",
       "      <td>Nestle mate French Vanilla Liquid Coffee</td>\n",
       "      <td>0.330147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reese's PIECES Peanut Butter Candy</td>\n",
       "      <td>Lay's Classic Potato Chips, Party Size</td>\n",
       "      <td>0.382681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reese's PIECES Peanut Butter Candy</td>\n",
       "      <td>Nestle mate French Vanilla Liquid Coffee</td>\n",
       "      <td>0.210759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lay's Classic Potato Chips, Party Size</td>\n",
       "      <td>Nestle mate French Vanilla Liquid Coffee</td>\n",
       "      <td>0.047231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0  \\\n",
       "0  3 Musketeers Milk Chocolate Bar, Full Size   \n",
       "1  3 Musketeers Milk Chocolate Bar, Full Size   \n",
       "2  3 Musketeers Milk Chocolate Bar, Full Size   \n",
       "3          Reese's PIECES Peanut Butter Candy   \n",
       "4          Reese's PIECES Peanut Butter Candy   \n",
       "5      Lay's Classic Potato Chips, Party Size   \n",
       "\n",
       "                                          1         2  \n",
       "0        Reese's PIECES Peanut Butter Candy  0.419337  \n",
       "1    Lay's Classic Potato Chips, Party Size  0.358077  \n",
       "2  Nestle mate French Vanilla Liquid Coffee  0.330147  \n",
       "3    Lay's Classic Potato Chips, Party Size  0.382681  \n",
       "4  Nestle mate French Vanilla Liquid Coffee  0.210759  \n",
       "5  Nestle mate French Vanilla Liquid Coffee  0.047231  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "distances = []\n",
    "for comb in list(itertools.combinations(range(4), 2)):\n",
    "    sim = util.cos_sim(embeddings[comb[0]], embeddings[comb[1]]).item()\n",
    "    result = sentence[comb[0]], sentence[comb[1]], sim\n",
    "    distances.append(result)\n",
    "    \n",
    "df = pd.DataFrame(distances)  \n",
    "df                                                                \n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15b10ec",
   "metadata": {},
   "source": [
    "### Scaling the Embedding Search: The Rise of the Vecor DB\n",
    "\n",
    "A relational database is designed to match on value either exactly or approximately.\n",
    "\n",
    " * Search using constraints\n",
    "\n",
    " * The type of data informs the search. \n",
    "\n",
    "  * Indexes built to store strings and numbers\n",
    "\n",
    " * Embedding have become so prevalent that various efforts to store and search them have gained a lot of attention \n",
    "\n",
    "* Indexing an embedding is a completely different matter. \n",
    "\n",
    "* Vector database allow you to customize the distance as you please\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18773da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e01c607",
   "metadata": {},
   "source": [
    "### What is a Vector \"Database\"?\n",
    "\n",
    "* Way we can improve the search:\n",
    " * reducing the number of dimsions reduces storage requirement and search .\n",
    "* Restrictinf the search by looking in specific neighborhoods\n",
    "\n",
    "* Vector database provide a way to search for a vector nearest neighbors.\n",
    "  * The search can be exaxt of approximate\n",
    "  * exact solution use carefully design data structure to bypass the linear scan of the data. \n",
    "\n",
    "\n",
    "* Vector databases are scalable, reliable and fast\n",
    "\n",
    "\n",
    "\n",
    "See https://zilliz.com/learn/what-is-vector-database\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bfaccb",
   "metadata": {},
   "source": [
    "### Examples of Vector \"Databases\"\n",
    "\n",
    "See the following for a list of libraries, standalone progrmas or managed services. \n",
    "\n",
    "[Awesome Vector Search Engine](https://github.com/currentslab/awesome-vector-search/blob/main/README.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2ed394",
   "metadata": {},
   "source": [
    "### Exmaples of Vector Databases toold and libraries - Faiss\n",
    "\n",
    "* A search library from Facebook AI \n",
    "  * Run on CPU or GPU and implements efficient exact and approaxiate searches\n",
    "* Can easily scale to millions or even billions of vectors\n",
    "\n",
    "\n",
    "[](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f360cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SAMPLE SCRIPT\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "word_embeds = []\n",
    "words = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for line in open(\"/Users/mahdi/Downloads/wiki-news-300d-1M.vec\"):\n",
    "    data = line.split()\n",
    "    words.append(data[0])\n",
    "    word_embeds.append(np.array(list(map(float, data[1:])), dtype=np.float32))\n",
    "    i+=1\n",
    "\n",
    "word_embeds = np.array(word_embeds, dtype=np.float32)\n",
    "faiss.normalize_L2(word_embeds)\n",
    "index = faiss.index_factory(300, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "\n",
    "\n",
    "index.add(word_embeds)\n",
    "index.ntotal\n",
    "\n",
    "\n",
    "q = word_embeds[words.index(\"woman\")].reshape(1, 300)\n",
    "%time\n",
    "res = index.search(q, 10)\n",
    "hits = res[1][0]\n",
    "scores = res[0][0]\n",
    "[(words[x],y) for x,y in zip(hits, scores)]\n",
    "\n",
    "%time\n",
    "res = index.search(q, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7bab0",
   "metadata": {},
   "source": [
    "### Flat L2 Index\n",
    "\n",
    "![](https://www.dropbox.com/s/fdhfq0bp1zqpqa3/lin_time_faiss.png?dl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49797c9e",
   "metadata": {},
   "source": [
    "### Adding Partitioning to Enable Approximate Search\n",
    "\n",
    "- Faiss supports multiple types of indexes, including the Inverted File Index IVF and product quantization IVFPQ\n",
    "\n",
    "- Partition the dataset and search in the partition where query has closest centroid \n",
    "\n",
    "![](https://www.dropbox.com/s/oa1j97wuhmk1t3z/partiton.png?dl=1)\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0026f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding Partitioning to Enable Approximate Search\n",
    "\n",
    "- Create multiple partitions to accomodate for the probabilistic nature\n",
    "  - Rigorous theoreical bound on seach accuracy \n",
    "\n",
    "\n",
    "![](https://www.dropbox.com/s/ag5n2ijlm8qy6pb/multiple_partitions.png?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d04dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random projections\n",
    "\n",
    "Project into a space of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a61cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
